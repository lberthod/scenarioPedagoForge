
# based on this github : https://github.com/nicknochnack/Langchain-Crash-Course
# Bring in deps
import os 

import streamlit as st 
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain, SequentialChain 
from langchain.memory import ConversationBufferMemory
from langchain.utilities import SerpAPIWrapper
from langchain.agents import Tool
from langchain.tools.file_management.write import WriteFileTool
from langchain.tools.file_management.read import ReadFileTool
    
os.environ['OPENAI_API_KEY'] = st.secrets["auth"]

# App framework
st.set_page_config(
   page_title="scenarioPedagoForge",
   page_icon="üßä",
)


# Titre principal
st.title('üìö scenarioPedagoForge    ')

# Description
st.write('üìö G√âN√âRATEUR DE SC√âNARIO P√âDAGOGIQUE')
st.write("Cet outil est con√ßu pour aider les enseignants √† √©laborer un sc√©nario p√©dagogique pour leurs cours √† partir d'une th√©matique de mati√®re.")
st.info("Veuillez fournir les informations ci-dessous afin de g√©n√©rer le contenu le plus adapt√© √† vos besoins. Toutes les informations sont facultatives mais contribuent √† am√©liorer la pr√©cision de la sortie g√©n√©r√©e.")

# Sous-titre
st.title('D√©crivez votre cours')

# Zone de saisie pour la th√©matique
st.info("Dans cette zone de saisie, vous pouvez fournir des informations sur votre cours et votre mati√®re pour aider √† √©laborer un sc√©nario p√©dagogique adapt√©.")
prompt_title = st.text_input('Th√©matique de cours') 

# Slider pour choisir la dur√©e du cours
st.write("Nombre de sections)")
numberQ = st.slider("S√©lectionnez le nombre de sous-sections", 1, 12, 1)

# Suite du code pour traiter les informations et g√©n√©rer le sc√©nario p√©dagogique...


# Prompt templates
title_template = PromptTemplate(
    input_variables = ['prompt_title' , 'numberQ'], 
    template = "En tant qu'expert en enseignement et en p√©dagogie, vous √™tes charg√©(e) de concevoir un cours sur la th√©matique suivante : {prompt_title} . Veuillez transmettre une introduction √† la th√©matique et expliciter les points importants √† apprendre sur ce sujet. Ensuite cr√©e une liste de  {numberQ} sous-th√©matique √†  pour am√©liorer la compr√©hension du sujet {prompt_title}  . Pour chaque sections, veuillez fournir uniquement le titre, sans sous explication de la th√©matique. Voici la th√©matique : \n\n1. {prompt_title}"

)

# Prompt templates
question_template = PromptTemplate(
    input_variables = ['list_question', 'number'], 
  template = "√Ä partir de la liste des sous sections suivante : {list_question}, reprenez la sous secftions {number}, reformulez-la  pr√©senter son sc√©anrio p√©dagogique avec des objectifs, les minimaux √† acqu√©rir. Veuillez √©num√©rer une par une, en sautant une ligne entre chacune, et fournir une explication d√©taill√©e pour chaque partie."

)


# Memory 
title_memory = ConversationBufferMemory(input_key='prompt_title', memory_key='chat_history')
listq_memory = ConversationBufferMemory(input_key='list_question', memory_key='list_question_history')

# Llms
llm = OpenAI(temperature=0.9, model_name="gpt-3.5-turbo-16k")
 
title_chain = LLMChain(llm=llm, prompt=title_template, verbose=True, output_key='list_question', memory=title_memory)
question_chain = LLMChain(llm=llm, prompt=question_template, verbose=True, output_key='question', memory=listq_memory)

# Show stuff to the screen if there's a prompt
if st.button('G√©n√©rer le sc√©nario'):

    list_question = title_chain.run(prompt_title=prompt_title, numberQ = numberQ)
    st.info('Proposition de sc√©nario : \n' +  list_question)
    number = 1
   
    for number in range(1, numberQ):
        question = question_chain.run(list_question=list_question, number=number)
        st.info(f'Sous-section : {number} : \n{question}')
        number = number + 1
